c3d.fc6 for svm c=0.01
=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
=========training===========
=========testing============
0.824477927571


=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 21:24:49
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=3000, n_jobs=-1, oob_score=True, random_state=50,
            verbose=0, warm_start=False)
start at test 2017-07-16 21:29:57
=========testing============
0.802537668517
end of all opt 2017-07-16 21:30:07

=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 21:45:02
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=5000, n_jobs=-1, oob_score=True, random_state=50,
            verbose=0, warm_start=False)
start at test 2017-07-16 21:53:33
=========testing============
0.803595030399
end of all opt 2017-07-16 21:53:49

=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 21:57:33
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=8000, n_jobs=-1, oob_score=True, random_state=50,
            verbose=0, warm_start=False)
start at test 2017-07-16 22:11:11
=========testing============
0.80385937087
feature importance : [ 0.00031853  0.00013229  0.00013152 ...,  0.00025743  0.00028215
  0.00018103]
end of all opt 2017-07-16 22:11:55


=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 22:40:09
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=3000, n_jobs=-1, oob_score=True, random_state=1,
            verbose=0, warm_start=False)
start at test 2017-07-16 22:45:16
=========testing============
0.805445413693
feature importance : [ 0.00030688  0.00013467  0.0001264  ...,  0.00027887  0.00027331
  0.00019475]
end of all opt 2017-07-16 22:45:26

=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 22:49:37
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=3000, n_jobs=-1, oob_score=True, random_state=0,
            verbose=0, warm_start=False)
start at test 2017-07-16 22:54:44
=========testing============
0.804916732752
feature importance : [ 0.000355    0.00012739  0.00012273 ...,  0.00027956  0.00027588
  0.00017714]
end of all opt 2017-07-16 22:54:54