c3d.fc6 for svm c=0.01
=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
=========training===========
=========testing============
0.824477927571


=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 21:24:49
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=3000, n_jobs=-1, oob_score=True, random_state=50,
            verbose=0, warm_start=False)
start at test 2017-07-16 21:29:57
=========testing============
0.802537668517
end of all opt 2017-07-16 21:30:07

=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 21:45:02
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=5000, n_jobs=-1, oob_score=True, random_state=50,
            verbose=0, warm_start=False)
start at test 2017-07-16 21:53:33
=========testing============
0.803595030399
end of all opt 2017-07-16 21:53:49

=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 21:57:33
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=8000, n_jobs=-1, oob_score=True, random_state=50,
            verbose=0, warm_start=False)
start at test 2017-07-16 22:11:11
=========testing============
0.80385937087
feature importance : [ 0.00031853  0.00013229  0.00013152 ...,  0.00025743  0.00028215
  0.00018103]
end of all opt 2017-07-16 22:11:55


=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 22:40:09
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=3000, n_jobs=-1, oob_score=True, random_state=1,
            verbose=0, warm_start=False)
start at test 2017-07-16 22:45:16
=========testing============
0.805445413693
feature importance : [ 0.00030688  0.00013467  0.0001264  ...,  0.00027887  0.00027331
  0.00019475]
end of all opt 2017-07-16 22:45:26

=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-16 22:49:37
=========training===========
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=50, max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=20, min_weight_fraction_leaf=0.0,
            n_estimators=3000, n_jobs=-1, oob_score=True, random_state=0,
            verbose=0, warm_start=False)
start at test 2017-07-16 22:54:44
=========testing============
0.804916732752
feature importance : [ 0.000355    0.00012739  0.00012273 ...,  0.00027956  0.00027588
  0.00017714]
end of all opt 2017-07-16 22:54:54

fc6 finetune c=0.01
=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-19 21:55:34
=========training===========
start at test 2017-07-19 21:57:36
=========testing============
0.867301083796
end of all opt 2017-07-19 21:59:11


32 without finetune c=0.01
=========data size==========
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-19 22:35:33
=========training===========
start at test 2017-07-19 22:37:37
=========testing============
0.819719799101
end of all opt 2017-07-19 22:39:18

32 without finetune and 16 fintune c=0.01
=========data size==========
num of the features : 8192
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-23 20:51:06
=========training===========
start at test 2017-07-23 20:55:30
=========testing============
0.871001850383
end of all opt 2017-07-23 20:58:41

32 finetune on 16 model c = 0.01
start at read 2017-07-25 11:03:22
=========data size==========
num of the features : 4096
train data size 9537
train label size 9537
test data size 3783
test label size 3783
start at train 2017-07-25 11:03:46
=========training===========
start at test 2017-07-25 11:06:25
=========testing============
0.793285752049
end of all opt 2017-07-25 11:08:16